{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"id":"aKGO5TwDP120","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"VAL_IMAGE_1 = \"./conditioning_image_1.png\"\nVAL_IMAGE_2 = \"./conditioning_image_1.png\" \n\nVAL_PROMPT_1 = \"red circle with blue background\"\nVAL_PROMPT_2 = \"cyan circle with brown floral background\"\n\nOUTPUT_DIR=\"controlnet-lambda\"\n\n \nDATASET_NAME = \"fusing/fill50k\"\nPRETRAINED_MODEL = \"stable-diffusion-v1-5/stable-diffusion-v1-5\"\n\n ","metadata":{"id":"Znww2Pb6r7s-","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q accelerate>=0.16.0 torchvision datasets diffusers bitsandbytes fsspec==2025.3.2","metadata":{"id":"a16NnBRxP6y0","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!accelerate config default","metadata":{"id":"yawRP9FYQI6R","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/docty/diffuser-training.git","metadata":{"id":"QBxXoCAIQN_n","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!git clone https://huggingface.co/Docty/{MODEL_ID}","metadata":{"id":"VzUgHBwxWTGj","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wget https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/controlnet_training/conditioning_image_1.png\n\nwget https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/controlnet_training/conditioning_image_2.png","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#--enable_xformers_memory_efficient_attention \\\n# --set_grads_to_none","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!accelerate launch --mixed_precision=\"fp16\" --multi_gpu {os.getcwd()}/diffuser-training/train_control.py \\\n  --pretrained_model_name_or_path=\"$PRETRAINED_MODEL\"  \\\n  --dataset_name=\"$DATASET_NAME\" \\\n  --output_dir=\"$OUTPUT_DIR\" \\\n  --resolution=128 \\\n  --learning_rate=1e-5 \\\n  --validation_image \"$VAL_IMAGE_1\" \"$VAL_IMAGE_1\" \\\n  --validation_prompt \"$VAL_PROMPT_1\" \"$VAL_PROMPT_2\" \\\n  --train_batch_size=1 \\\n  --gradient_accumulation_steps=4 \\\n  --gradient_checkpointing \\\n  --use_8bit_adam \\\n  --mixed_precision=\"fp16\" \\\n  --tracker_project_name=\"controlnet-demo\" \\\n  --push_to_hub","metadata":{"id":"3sh7FRUaCjou"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inference","metadata":{"id":"CULI4CqvvzWL"}},{"cell_type":"code","source":"from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler\nfrom diffusers.utils import load_image\nimport torch\n\n\nMODEL_ID = OUTPUT_DIR\ncontrolnet_model_id = f\"Docty/{MODEL_ID}\"\ncard = RepoCard.load(lora_model_id)\nbase_model_id = card.data.to_dict()[\"base_model\"]\n\n\ncontrolnet = ControlNetModel.from_pretrained(controlnet_model_id, torch_dtype=torch.float16)\npipe = StableDiffusionControlNetPipeline.from_pretrained(\n    base_model_id, controlnet=controlnet, torch_dtype=torch.float16\n)\n\n# speed up diffusion process with faster scheduler and memory optimization\npipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n# remove following line if xformers is not installed or when using Torch 2.0.\n#pipe.enable_xformers_memory_efficient_attention()\n# memory optimization.\npipe.enable_model_cpu_offload()\n\n","metadata":{"id":"B0KxQ80p3d20","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"control_image = load_image(VAL_IMAGE_1)\nprompt = \"pale golden rod circle with old lace background\"\n\n \ngenerator = torch.manual_seed(0)\nimage = pipe(\n    prompt, num_inference_steps=20, generator=generator, image=control_image\n).images[0]\n\nimage","metadata":{"id":"11nRpjkt3sZS","trusted":true},"outputs":[],"execution_count":null}]}